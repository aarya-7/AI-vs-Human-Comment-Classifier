# AI-vs-Human-Comment-Classifier
This project develops a machine learning model to distinguish between comments generated by AI and those written by humans. The ability to identify AI-generated text is important as language models become more prevalent and sophisticated. This classifier aims to enhance transparency and accountability in digital communications.

**Data Collection**
Sourcing the Dataset: Gathered a comprehensive dataset comprising both AI-generated and human-written comments.
Link: https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text

**Data Preprocessing**
Cleaning Text Data: Implemented text cleaning techniques to normalize the dataset. This included removing stop words, punctuation, and lemmatizing the words to reduce them to their base or root form.

**Feature Engineering:** Extracted important features that could potentially differentiate AI-generated text from human-written text. These features included:
Length of Text: Counting the number of characters and words in each comment to capture verbosity tendencies in human vs. AI writing.
Readability Scores: Calculating Flesch Reading Ease and Flesch-Kincaid Grade Levels to assess the text's complexity, which often varies between humans and machines.

**Model Development**
Choosing a Model: After evaluating several machine learning algorithms, I chose a model that best fits the problem's nature based on accuracy, performance, and computational efficiency. For this project, I chose Logistic Regression.
Training the Model: I trained the classifier using the features extracted from the preprocessing step, optimizing for both accuracy and generalizability to handle unseen data effectively.
Model Evaluation: I tested the model to evaluate its performance. Metrics such as precision, recall, and F1-score were calculated to ensure the model's reliability in classifying comments accurately.
Precision: 0.9909797830319367
Recall: 0.9909797120486008
F1 Score: 0.9909738890559167
